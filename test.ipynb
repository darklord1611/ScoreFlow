{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "pkl_path = \"/teamspace/studios/this_studio/modal_remote/ScoreFlow/runs/Qwen-Qwen2.5-7B-Instruct_MATH_0/Qwen-Qwen2.5-7B-Instruct_MATH_0.pkl\"\n",
    "\n",
    "if not os.path.exists(pkl_path):\n",
    "    raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file {pkl_path}\")\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_prob = \"A particular convex pentagon has two congruent, acute angles. The measure of each of the other interior angles is equal to the sum of the measures of the two acute angles. What is the common measure of the large angles, in degrees?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_num = 8  # number of graph variants per problem\n",
    "\n",
    "# Assume `data` is already loaded (from the pickle)\n",
    "print(f\"Total records: {len(data)}\")\n",
    "num_problems = len(data) // graph_num\n",
    "print(f\"Expecting {num_problems} unique problems (8 graphs each)\\n\")\n",
    "\n",
    "error_groups = []\n",
    "\n",
    "for group_idx in range(num_problems):\n",
    "    start = group_idx * graph_num\n",
    "    end = start + graph_num\n",
    "    group = data[start:end]\n",
    "    \n",
    "    # Reference problem text (normalize whitespace)\n",
    "    ref_prob = group[0][0][\"problem\"].strip()\n",
    "    all_same = all(\n",
    "        (item[0][\"problem\"].strip() == ref_prob)\n",
    "        for item in group\n",
    "    )\n",
    "    \n",
    "    if not all_same:\n",
    "        print(f\"‚ùå Mismatch found in group {group_idx} (indices {start}-{end-1})\")\n",
    "        for idx, item in enumerate(group, start=start):\n",
    "            print(f\"  idx={idx} ‚Üí {item[0]['problem'][:80]!r}\")\n",
    "        error_groups.append(group_idx)\n",
    "\n",
    "if not error_groups:\n",
    "    print(\"\\n‚úÖ All problems are grouped correctly (8 per problem, contiguous).\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Found {len(error_groups)} groups with mismatched problems: {error_groups}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"runs/Qwen-Qwen2.5-7B-Instruct_MATH_0/Qwen-Qwen2.5-7B-Instruct_MATH_0.json\", \"r\") as f:\n",
    "    workflow_data = json.load(f)\n",
    "\n",
    "len(workflow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"part_1.json\", \"r\") as f:\n",
    "    part1_eval = json.load(f)\n",
    "\n",
    "len(part1_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"part_1.json\", \"r\") as f:\n",
    "    part1_eval = json.load(f)\n",
    "\n",
    "len(part1_eval)\n",
    "\n",
    "with open(\"runs/Qwen-Qwen2.5-7B-Instruct_MATH_0/Qwen-Qwen2.5-7B-Instruct_MATH_0_scores_0_named.json\", \"r\") as f:\n",
    "    part2_eval = json.load(f)\n",
    "\n",
    "len(part2_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Part 1 entries: {len(part1_eval)}\")\n",
    "print(f\"Part 2 entries: {len(part2_eval)}\")\n",
    "\n",
    "# === Merge while removing duplicates ===\n",
    "merged = []\n",
    "seen_keys = set()\n",
    "\n",
    "def key(entry):\n",
    "    return (entry[\"question_id\"], entry[\"graph_id\"], entry[\"rep_id\"])\n",
    "\n",
    "for entry in part1_eval + part2_eval:\n",
    "    k = key(entry)\n",
    "    if k not in seen_keys:\n",
    "        merged.append(entry)\n",
    "        seen_keys.add(k)\n",
    "\n",
    "print(f\"‚úÖ Merged entries: {len(merged)} (removed {len(part1_eval) + len(part2_eval) - len(merged)} duplicates)\")\n",
    "\n",
    "# === Save result ===\n",
    "output_file = \"merged_eval.json\"\n",
    "# with open(output_file, \"w\") as f:\n",
    "#     json.dump(merged, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üíæ Saved merged file ‚Üí {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = []\n",
    "\n",
    "for item in workflow_data:\n",
    "    cur = {\n",
    "        \"problem\": item[0][\"problem\"],\n",
    "        \"level\": item[0][\"level\"],\n",
    "        \"type\": item[0][\"type\"],\n",
    "        \"solution\": item[0][\"solution\"],\n",
    "        \"graph\": item[1]\n",
    "    }\n",
    "    temp_data.append(cur)\n",
    "\n",
    "temp_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in merged:\n",
    "    item[\"problem\"] = temp_data[item[\"question_id\"] + item[\"graph_id\"]][\"problem\"]\n",
    "    item[\"level\"] = temp_data[item[\"question_id\"] + item[\"graph_id\"]][\"level\"]\n",
    "    item[\"type\"] = temp_data[item[\"question_id\"] + item[\"graph_id\"]][\"type\"]\n",
    "    item[\"solution\"] = temp_data[item[\"question_id\"] + item[\"graph_id\"]][\"solution\"]\n",
    "\n",
    "    break\n",
    "\n",
    "merged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(merged, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/teamspace/studios/this_studio/modal_remote/ScoreFlow/scoreflow_workspace/temp_gene_workflow_file/fail_checkpoint_epoch_100.pkl\", \"r\") as f:\n",
    "    data = pickle.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/teamspace/studios/this_studio/modal_remote/ScoreFlow/scoreflow_workspace/temp_gene_workflow_file/fail_checkpoint_epoch_100.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
